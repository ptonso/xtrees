{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from src.experiments.experiment import *\n",
    "from src.experiments.ExperimentSupervised import *\n",
    "from src.xtrees.ForestBasedTree import *\n",
    "from src.experiments.exact_paper import PrevPaperClassifier, fit_paper_fbt\n",
    "\n",
    "SEED = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populated data-params with 1 datasets of overall size medium, information level mixed, and prediction level mixed.\n",
      "\n",
      "Dataset ID: 1\n",
      "n_samples     | n_features    | n_informative | n_classes     | n_redundant   | n_repeated    | random_state \n",
      "=============================================================================================================\n",
      "1300          | 70            | 35            | 6             | 21            | 7             | 7            \n",
      "\n",
      "RandomForestClassifier\n",
      "Running cross-validation with 3 folds...\n",
      "DecisionTreeClassifier\n",
      "Running cross-validation with 3 folds...\n",
      "ForestBasedTree\n",
      "Running cross-validation with 3 folds...\n",
      "PrevPaperClassifier\n",
      "Running cross-validation with 3 folds...\n",
      "0.8254441593906843 [72, 49]\n",
      "0.8651715567313282 [72, 49, 22]\n",
      "0.892709705636064 [72, 49, 22, 85]\n",
      "0.9130172970147582 [72, 49, 22, 85, 5]\n",
      "0.9277877635487948 [72, 49, 22, 85, 5, 45]\n",
      "0.9393207068147998 [72, 49, 22, 85, 5, 45, 70]\n",
      "0.948427107723653 [72, 49, 22, 85, 5, 45, 70, 79]\n",
      "0.9556899338094502 [72, 49, 22, 85, 5, 45, 70, 79, 25]\n",
      "0.9606648923403507 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75]\n",
      "0.9659812042306481 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86]\n",
      "0.9699019675820982 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47]\n",
      "0.9732154953090582 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40]\n",
      "0.9758815183824117 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82]\n",
      "0.9781061822293575 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87]\n",
      "0.9802145725882585 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81]\n",
      "0.9818178666481767 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13]\n",
      "0.9833992927585083 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50]\n",
      "0.98460869704356 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29]\n",
      "0.9855871544463941 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14]\n",
      "0.986524542773176 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78]\n",
      "0.9874976665297698 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56]\n",
      "0.9883059806175295 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67]\n",
      "0.9889670860690494 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7]\n",
      "0.9894185792233144 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89]\n",
      "0.9898543381211697 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36]\n",
      "0.9902540949069012 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90]\n",
      "0.9906413176239672 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26]\n",
      "0.9909578695283455 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92]\n",
      "0.9912328189920475 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73]\n",
      "0.9914979012102043 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4]\n",
      "0.9917557830059363 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1]\n",
      "0.9919688621732474 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18]\n",
      "0.9921902084922316 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74]\n",
      "0.9924027542949186 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20]\n",
      "0.9926008992527562 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24]\n",
      "0.9927481078889961 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3]\n",
      "0.9929137176047662 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3, 6]\n",
      "0.9930454586669084 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3, 6, 28]\n",
      "0.9931998677255732 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3, 6, 28, 15]\n",
      "0.9933182746721141 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3, 6, 28, 15, 88]\n",
      "0.9934164137629408 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3, 6, 28, 15, 88, 34]\n",
      "0.9935246867816245 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3, 6, 28, 15, 88, 34, 12]\n",
      "0.9936356266234286 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3, 6, 28, 15, 88, 34, 12, 60]\n",
      "0.9937081642123003 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3, 6, 28, 15, 88, 34, 12, 60, 19]\n",
      "0.993814837137112 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3, 6, 28, 15, 88, 34, 12, 60, 19, 54]\n",
      "0.9939041757116417 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3, 6, 28, 15, 88, 34, 12, 60, 19, 54, 59]\n",
      "0.9939553787155513 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3, 6, 28, 15, 88, 34, 12, 60, 19, 54, 59, 11]\n",
      "0.9940167156473181 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3, 6, 28, 15, 88, 34, 12, 60, 19, 54, 59, 11, 43]\n",
      "0.9940625850049869 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3, 6, 28, 15, 88, 34, 12, 60, 19, 54, 59, 11, 43, 66]\n",
      "0.994062851687299 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3, 6, 28, 15, 88, 34, 12, 60, 19, 54, 59, 11, 43, 66, 46]\n",
      "0.9940921867416221 [72, 49, 22, 85, 5, 45, 70, 79, 25, 75, 86, 47, 40, 82, 87, 81, 13, 50, 29, 14, 78, 56, 67, 7, 89, 36, 90, 26, 92, 73, 4, 1, 18, 74, 20, 24, 3, 6, 28, 15, 88, 34, 12, 60, 19, 54, 59, 11, 43, 66, 46, 69]\n",
      "Finish pruning\n",
      "Iteration 1: 28 conjunctions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonso/code/00_active/xtrees_experiment/src/experiments/exact_paper.py:51: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if self.feature_types[i]=='int' and min(self.features_upper[i],other_branch.features_upper[i])%1>0 and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2: 50 conjunctions\n",
      "Iteration 3: 50 conjunctions\n",
      "Iteration 4: 50 conjunctions\n",
      "Iteration 5: 50 conjunctions\n",
      "Iteration 6: 50 conjunctions\n",
      "Iteration 7: 50 conjunctions\n",
      "Iteration 8: 50 conjunctions\n",
      "Iteration 9: 50 conjunctions\n",
      "Iteration 10: 50 conjunctions\n",
      "Iteration 11: 50 conjunctions\n",
      "Iteration 12: 50 conjunctions\n",
      "Iteration 13: 50 conjunctions\n",
      "Iteration 14: 50 conjunctions\n",
      "Iteration 15: 50 conjunctions\n",
      "Iteration 16: 50 conjunctions\n",
      "Iteration 17: 50 conjunctions\n",
      "Iteration 18: 50 conjunctions\n",
      "Iteration 19: 50 conjunctions\n",
      "Iteration 20: 50 conjunctions\n",
      "Iteration 21: 50 conjunctions\n",
      "Iteration 22: 50 conjunctions\n",
      "Iteration 23: 50 conjunctions\n",
      "Iteration 24: 50 conjunctions\n",
      "Iteration 25: 50 conjunctions\n",
      "Iteration 26: 50 conjunctions\n",
      "Iteration 27: 50 conjunctions\n",
      "Iteration 28: 50 conjunctions\n",
      "Iteration 29: 50 conjunctions\n",
      "Iteration 30: 50 conjunctions\n",
      "Iteration 31: 50 conjunctions\n",
      "Iteration 32: 50 conjunctions\n",
      "Iteration 33: 50 conjunctions\n",
      "Iteration 34: 50 conjunctions\n",
      "Iteration 35: 50 conjunctions\n",
      "Iteration 36: 50 conjunctions\n",
      "Iteration 37: 50 conjunctions\n",
      "Iteration 38: 50 conjunctions\n",
      "Iteration 39: 50 conjunctions\n",
      "Iteration 40: 50 conjunctions\n",
      "Iteration 41: 50 conjunctions\n",
      "Iteration 42: 50 conjunctions\n",
      "Iteration 43: 50 conjunctions\n",
      "Iteration 44: 50 conjunctions\n",
      "Iteration 45: 50 conjunctions\n",
      "Iteration 46: 50 conjunctions\n",
      "Iteration 47: 50 conjunctions\n",
      "Iteration 48: 50 conjunctions\n",
      "Iteration 49: 50 conjunctions\n",
      "Iteration 50: 50 conjunctions\n",
      "Iteration 51: 50 conjunctions\n",
      "Final CS size: 50\n",
      "0.8284778678416207 [46, 64]\n",
      "0.8651957125885839 [46, 64, 26]\n",
      "0.8902230842808662 [46, 64, 26, 8]\n",
      "0.9099181975524452 [46, 64, 26, 8, 48]\n",
      "0.9248263577091058 [46, 64, 26, 8, 48, 61]\n",
      "0.9354770390414121 [46, 64, 26, 8, 48, 61, 40]\n",
      "0.944159353136736 [46, 64, 26, 8, 48, 61, 40, 9]\n",
      "0.9506317107207901 [46, 64, 26, 8, 48, 61, 40, 9, 83]\n",
      "0.9564971683768153 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68]\n",
      "0.9613223021755009 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62]\n",
      "0.9653252874526566 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63]\n",
      "0.9684890958893905 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91]\n",
      "0.9714642624808931 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94]\n",
      "0.9743234236499403 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13]\n",
      "0.9762587985190683 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99]\n",
      "0.9782423316025644 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32]\n",
      "0.9797543931067236 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80]\n",
      "0.9811187871579868 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52]\n",
      "0.9821649644999462 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1]\n",
      "0.9832811175898544 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12]\n",
      "0.9842791367174457 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44]\n",
      "0.9851326812019332 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44, 70]\n",
      "0.9859793079318707 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44, 70, 58]\n",
      "0.986751967901619 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44, 70, 58, 49]\n",
      "0.9873817496331594 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44, 70, 58, 49, 42]\n",
      "0.9879053704391045 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44, 70, 58, 49, 42, 89]\n",
      "0.988464378220248 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44, 70, 58, 49, 42, 89, 20]\n",
      "0.988971502842266 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44, 70, 58, 49, 42, 89, 20, 41]\n",
      "0.989361291704415 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44, 70, 58, 49, 42, 89, 20, 41, 33]\n",
      "0.9896685996469284 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44, 70, 58, 49, 42, 89, 20, 41, 33, 17]\n",
      "0.9900099642272269 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44, 70, 58, 49, 42, 89, 20, 41, 33, 17, 96]\n",
      "0.990283481599438 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44, 70, 58, 49, 42, 89, 20, 41, 33, 17, 96, 35]\n",
      "0.9905708344807493 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44, 70, 58, 49, 42, 89, 20, 41, 33, 17, 96, 35, 16]\n",
      "0.9908523338774413 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44, 70, 58, 49, 42, 89, 20, 41, 33, 17, 96, 35, 16, 0]\n",
      "0.9910529487593938 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44, 70, 58, 49, 42, 89, 20, 41, 33, 17, 96, 35, 16, 0, 29]\n",
      "0.9912245622857325 [46, 64, 26, 8, 48, 61, 40, 9, 83, 68, 62, 63, 91, 94, 13, 99, 32, 80, 52, 1, 12, 44, 70, 58, 49, 42, 89, 20, 41, 33, 17, 96, 35, 16, 0, 29, 22]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'meta-params': {\n",
    "        'is_classification': True,\n",
    "        'random_state': SEED,\n",
    "        'use_cross_validation': True,\n",
    "        'cv_folds': 3\n",
    "    },\n",
    "    'data-params': [],\n",
    "    'model-params': {}\n",
    "}\n",
    "\n",
    "rf_class = RandomForestClassifier(random_state=params['meta-params']['random_state'], n_estimators=10, max_depth=5)\n",
    "dtrand_class = DecisionTreeClassifier(random_state=params['meta-params']['random_state'])\n",
    "fbt_class = ForestBasedTree(random_state=params['meta-params']['random_state'], verbose=False)\n",
    "paper_class = PrevPaperClassifier()\n",
    "\n",
    "\n",
    "fitclass = FitClass(SEED)\n",
    "\n",
    "model_instances = [rf_class, dtrand_class, fbt_class, paper_class]\n",
    "fit_functions = [fitclass.fit_rf_class, \n",
    "                 fitclass.fit_dtrand_class, \n",
    "                 fitclass.fit_fbt_class,\n",
    "                 fit_paper_fbt]\n",
    "\n",
    "exp2 = Experiment(params)\n",
    "exp2.perform_experiments(num_datasets=1, \n",
    "                        overall_size='medium', \n",
    "                        information='mixed', \n",
    "                        prediction='mixed', \n",
    "                        model_instances=model_instances, \n",
    "                        fit_functions=fit_functions)\n",
    "\n",
    "results_class_df = exp2.assemble_results_dataframe()\n",
    "\n",
    "results_class_df.to_csv(f'data/results/class_experiment{SEED}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | model_name             | train_time (s)   | pred_time (s)   | accuracy     |\n",
      "|---:|:-----------------------|:-----------------|:----------------|:-------------|\n",
      "|  0 | DecisionTreeClassifier | 0.7323 ± nan     | 0.0004 ± nan    | 0.2465 ± nan |\n",
      "|  1 | ForestBasedTree        | 3.899 ± nan      | 0.0055 ± nan    | 0.2003 ± nan |\n",
      "|  2 | PrevPaperClassifier    | 61.3704 ± nan    | 0.2666 ± nan    | 0.2001 ± nan |\n",
      "|  3 | RandomForestClassifier | 0.0224 ± nan     | 0.0013 ± nan    | 0.3152 ± nan |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "avg_df = average_class_metrics(results_class_df)\n",
    "print(avg_df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
