{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from src.experiments.experiment import *\n",
    "from src.experiments.ExperimentSupervised import *\n",
    "from src.xtrees.ForestBasedTree import *\n",
    "from src.experiments.exact_paper import PrevPaperClassifier, fit_paper_fbt\n",
    "\n",
    "SEED = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populated data-params with 1 datasets of overall size medium, information level mixed, and prediction level mixed.\n",
      "\n",
      "Dataset ID: 1\n",
      "n_samples     | n_features    | n_informative | n_classes     | n_redundant   | n_repeated    | random_state \n",
      "=============================================================================================================\n",
      "1300          | 100           | 50            | 7             | 20            | 20            | 4            \n",
      "\n",
      "RandomForestClassifier\n",
      "Running cross-validation with 3 folds...\n",
      "DecisionTreeClassifier\n",
      "Running cross-validation with 3 folds...\n",
      "ForestBasedTree\n",
      "Running cross-validation with 3 folds...\n",
      "PrevPaperClassifier\n",
      "Running cross-validation with 3 folds...\n",
      "0.7878299971376099 [63, 9]\n",
      "0.8327974130037852 [63, 9, 76]\n",
      "0.8630199638378786 [63, 9, 76, 86]\n",
      "0.8882211089717263 [63, 9, 76, 86, 43]\n",
      "0.9054857884995919 [63, 9, 76, 86, 43, 33]\n",
      "0.9200553099115147 [63, 9, 76, 86, 43, 33, 85]\n",
      "0.9305648153580566 [63, 9, 76, 86, 43, 33, 85, 58]\n",
      "0.9402060476436841 [63, 9, 76, 86, 43, 33, 85, 58, 84]\n",
      "0.9476871532018768 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50]\n",
      "0.9540026348212429 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3]\n",
      "0.959940538733828 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83]\n",
      "0.9643016834765418 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97]\n",
      "0.9678663370473289 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19]\n",
      "0.9711889764199502 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36]\n",
      "0.9742340439528008 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34]\n",
      "0.9767886382667783 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20]\n",
      "0.9790727722693064 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98]\n",
      "0.9813609065065151 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67]\n",
      "0.983110120238165 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26]\n",
      "0.9848560004409147 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56]\n",
      "0.9859729548577961 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12]\n",
      "0.9870183495209497 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47]\n",
      "0.988006851957537 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24]\n",
      "0.9888820144115121 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14]\n",
      "0.9895460533684644 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54]\n",
      "0.9902454277317603 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37]\n",
      "0.9907923487066796 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17]\n",
      "0.9912788216908724 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48]\n",
      "0.9917004019791383 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61]\n",
      "0.9921810968465705 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16]\n",
      "0.9926513466567816 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11]\n",
      "0.9930838164727886 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66]\n",
      "0.9935178419356157 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4]\n",
      "0.9938560840013725 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41]\n",
      "0.9942036599480503 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60]\n",
      "0.9945290123687256 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30]\n",
      "0.9948043618558955 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28]\n",
      "0.9950379311141809 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29]\n",
      "0.9952997242504893 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69]\n",
      "0.9954959579850907 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38]\n",
      "0.9956886359555316 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27]\n",
      "0.9958664241635509 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71]\n",
      "0.9960013209663856 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5]\n",
      "0.9961075494206771 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64]\n",
      "0.9962426684587719 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77]\n",
      "0.9963397852674024 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40]\n",
      "0.9964111227858701 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53]\n",
      "0.9964762377170571 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42]\n",
      "0.9965377968840838 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81]\n",
      "0.9966240241649732 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81, 80]\n",
      "0.9967006953296815 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81, 80, 32]\n",
      "0.9967540317920873 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81, 80, 32, 68]\n",
      "0.9968233691932149 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81, 80, 32, 68, 35]\n",
      "0.9968882618891418 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81, 80, 32, 68, 35, 44]\n",
      "0.9969467097625283 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81, 80, 32, 68, 35, 44, 75]\n",
      "0.996999157283894 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81, 80, 32, 68, 35, 44, 75, 92]\n",
      "0.9970511603347396 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81, 80, 32, 68, 35, 44, 75, 92, 99]\n",
      "0.9970951629162245 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81, 80, 32, 68, 35, 44, 75, 92, 99, 70]\n",
      "0.9971351652630287 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81, 80, 32, 68, 35, 44, 75, 92, 99, 70, 8]\n",
      "0.9971622779647518 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81, 80, 32, 68, 35, 44, 75, 92, 99, 70, 8, 72]\n",
      "0.9971998357236957 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81, 80, 32, 68, 35, 44, 75, 92, 99, 70, 8, 72, 15]\n",
      "0.9972278373664588 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81, 80, 32, 68, 35, 44, 75, 92, 99, 70, 8, 72, 15, 87]\n",
      "0.9972553945387018 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81, 80, 32, 68, 35, 44, 75, 92, 99, 70, 8, 72, 15, 87, 7]\n",
      "0.9972707287716435 [63, 9, 76, 86, 43, 33, 85, 58, 84, 50, 3, 83, 97, 19, 36, 34, 20, 98, 67, 26, 56, 12, 47, 24, 14, 54, 37, 17, 48, 61, 16, 11, 66, 4, 41, 60, 30, 28, 29, 69, 38, 27, 71, 5, 64, 77, 40, 53, 42, 81, 80, 32, 68, 35, 44, 75, 92, 99, 70, 8, 72, 15, 87, 7, 93]\n",
      "Finish pruning\n",
      "Iteration 1: 29 conjunctions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonso/code/00_active/xtrees_experiment/src/experiments/exact_paper.py:51: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if self.feature_types[i]=='int' and min(self.features_upper[i],other_branch.features_upper[i])%1>0 and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2: 50 conjunctions\n",
      "Iteration 3: 50 conjunctions\n",
      "Iteration 4: 50 conjunctions\n",
      "Iteration 5: 50 conjunctions\n",
      "Iteration 6: 50 conjunctions\n",
      "Iteration 7: 50 conjunctions\n",
      "Iteration 8: 50 conjunctions\n",
      "Iteration 9: 50 conjunctions\n",
      "Iteration 10: 50 conjunctions\n",
      "Iteration 11: 50 conjunctions\n",
      "Iteration 12: 50 conjunctions\n",
      "Iteration 13: 50 conjunctions\n",
      "Iteration 14: 50 conjunctions\n",
      "Iteration 15: 50 conjunctions\n",
      "Iteration 16: 50 conjunctions\n",
      "Iteration 17: 50 conjunctions\n",
      "Iteration 18: 50 conjunctions\n",
      "Iteration 19: 50 conjunctions\n",
      "Iteration 20: 50 conjunctions\n",
      "Iteration 21: 50 conjunctions\n",
      "Iteration 22: 50 conjunctions\n",
      "Iteration 23: 50 conjunctions\n",
      "Iteration 24: 50 conjunctions\n",
      "Iteration 25: 50 conjunctions\n",
      "Iteration 26: 50 conjunctions\n",
      "Iteration 27: 50 conjunctions\n",
      "Iteration 28: 50 conjunctions\n",
      "Iteration 29: 50 conjunctions\n",
      "Iteration 30: 50 conjunctions\n",
      "Iteration 31: 50 conjunctions\n",
      "Iteration 32: 50 conjunctions\n",
      "Iteration 33: 50 conjunctions\n",
      "Iteration 34: 50 conjunctions\n",
      "Iteration 35: 50 conjunctions\n",
      "Iteration 36: 50 conjunctions\n",
      "Iteration 37: 50 conjunctions\n",
      "Iteration 38: 50 conjunctions\n",
      "Iteration 39: 50 conjunctions\n",
      "Iteration 40: 50 conjunctions\n",
      "Iteration 41: 50 conjunctions\n",
      "Iteration 42: 50 conjunctions\n",
      "Iteration 43: 50 conjunctions\n",
      "Iteration 44: 50 conjunctions\n",
      "Iteration 45: 50 conjunctions\n",
      "Iteration 46: 50 conjunctions\n",
      "Iteration 47: 50 conjunctions\n",
      "Iteration 48: 50 conjunctions\n",
      "Iteration 49: 50 conjunctions\n",
      "Iteration 50: 50 conjunctions\n",
      "Iteration 51: 50 conjunctions\n",
      "Iteration 52: 50 conjunctions\n",
      "Iteration 53: 50 conjunctions\n",
      "Iteration 54: 50 conjunctions\n",
      "Iteration 55: 50 conjunctions\n",
      "Iteration 56: 50 conjunctions\n",
      "Iteration 57: 50 conjunctions\n",
      "Iteration 58: 50 conjunctions\n",
      "Iteration 59: 50 conjunctions\n",
      "Iteration 60: 50 conjunctions\n",
      "Iteration 61: 50 conjunctions\n",
      "Iteration 62: 50 conjunctions\n",
      "Iteration 63: 50 conjunctions\n",
      "Iteration 64: 50 conjunctions\n",
      "Final CS size: 50\n",
      "0.8036522861626727 [7, 28]\n",
      "0.8454052584690388 [7, 28, 37]\n",
      "0.876233389074471 [7, 28, 37, 55]\n",
      "0.8965984159228971 [7, 28, 37, 55, 15]\n",
      "0.9129881728569484 [7, 28, 37, 55, 15, 92]\n",
      "0.9256826959021617 [7, 28, 37, 55, 15, 92, 72]\n",
      "0.9359970235917602 [7, 28, 37, 55, 15, 92, 72, 84]\n",
      "0.9449007501772674 [7, 28, 37, 55, 15, 92, 72, 84, 58]\n",
      "0.9522204883491266 [7, 28, 37, 55, 15, 92, 72, 84, 58, 77]\n",
      "0.9577883938703373 [7, 28, 37, 55, 15, 92, 72, 84, 58, 77, 8]\n",
      "0.9624212939127751 [7, 28, 37, 55, 15, 92, 72, 84, 58, 77, 8, 46]\n",
      "0.9664817054216128 [7, 28, 37, 55, 15, 92, 72, 84, 58, 77, 8, 46, 70]\n",
      "0.9702640764110334 [7, 28, 37, 55, 15, 92, 72, 84, 58, 77, 8, 46, 70, 81]\n",
      "0.9732622134952088 [7, 28, 37, 55, 15, 92, 72, 84, 58, 77, 8, 46, 70, 81, 4]\n",
      "0.9757918500869375 [7, 28, 37, 55, 15, 92, 72, 84, 58, 77, 8, 46, 70, 81, 4, 24]\n",
      "0.978181801250251 [7, 28, 37, 55, 15, 92, 72, 84, 58, 77, 8, 46, 70, 81, 4, 24, 45]\n",
      "0.9800706586544878 [7, 28, 37, 55, 15, 92, 72, 84, 58, 77, 8, 46, 70, 81, 4, 24, 45, 86]\n",
      "0.9818306950525195 [7, 28, 37, 55, 15, 92, 72, 84, 58, 77, 8, 46, 70, 81, 4, 24, 45, 86, 60]\n",
      "0.983131543319999 [7, 28, 37, 55, 15, 92, 72, 84, 58, 77, 8, 46, 70, 81, 4, 24, 45, 86, 60, 99]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'meta-params': {\n",
    "        'is_classification': True,\n",
    "        'random_state': SEED,\n",
    "        'use_cross_validation': True,\n",
    "        'cv_folds': 3\n",
    "    },\n",
    "    'data-params': [],\n",
    "    'model-params': {}\n",
    "}\n",
    "\n",
    "rf_class = RandomForestClassifier(random_state=params['meta-params']['random_state'], n_estimators=10, max_depth=5)\n",
    "dtrand_class = DecisionTreeClassifier(random_state=params['meta-params']['random_state'])\n",
    "fbt_class = ForestBasedTree(random_state=params['meta-params']['random_state'], verbose=False)\n",
    "paper_class = PrevPaperClassifier()\n",
    "\n",
    "\n",
    "fitclass = FitClass(SEED)\n",
    "\n",
    "model_instances = [rf_class, dtrand_class, fbt_class, paper_class]\n",
    "fit_functions = [fitclass.fit_rf_class, \n",
    "                 fitclass.fit_dtrand_class, \n",
    "                 fitclass.fit_fbt_class,\n",
    "                 fit_paper_fbt]\n",
    "\n",
    "exp2 = Experiment(params)\n",
    "exp2.perform_experiments(num_datasets=1, \n",
    "                        overall_size='medium', \n",
    "                        information='mixed', \n",
    "                        prediction='mixed', \n",
    "                        model_instances=model_instances, \n",
    "                        fit_functions=fit_functions)\n",
    "\n",
    "results_class_df = exp2.assemble_results_dataframe()\n",
    "\n",
    "results_class_df.to_csv(f'data/results/class_experiment{SEED}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | model_name             | train_time (s)   | pred_time (s)   | accuracy     |\n",
      "|---:|:-----------------------|:-----------------|:----------------|:-------------|\n",
      "|  0 | DecisionTreeClassifier | 0.6059 ± nan     | 0.0002 ± nan    | 0.2081 ± nan |\n",
      "|  1 | ForestBasedTree        | 3.6543 ± nan     | 0.0061 ± nan    | 0.2077 ± nan |\n",
      "|  2 | PrevPaperClassifier    | 61.8745 ± nan    | 0.3845 ± nan    | 0.2074 ± nan |\n",
      "|  3 | RandomForestClassifier | 0.0136 ± nan     | 0.0007 ± nan    | 0.3159 ± nan |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "avg_df = average_class_metrics(results_class_df)\n",
    "print(avg_df.to_markdown())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
